{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XRD Deep learning CNN\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "#from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "\n",
    "# hyper parameters\n",
    "num_files = 6010\n",
    "num_files_te = 1000\n",
    "vld_num_files = 1000\n",
    "X_length = 4511\n",
    "X_length_ = 4501\n",
    "\n",
    "level_num = 5\n",
    "\n",
    "lstm_layers = 2        # Number of layers\n",
    "\n",
    "batch_size_ = 1000       # Batch size\n",
    "batch_size = 1000 \n",
    "\n",
    "learning_rate = 0.001  # Learning rate (default is 0.001)\n",
    "epochs = 1\n",
    "\n",
    "# Fixed\n",
    "n_classes = 38\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-b0bc03f4a078>:7: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\sohn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\sohn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From C:\\Users\\sohn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\sohn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\sohn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:202: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-2-b0bc03f4a078>:9: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "WARNING:tensorflow:From C:\\Users\\sohn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"add_1:0\", shape=(190,), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-2-b0bc03f4a078>:63: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "Tensor(\"batch:0\", shape=(1000, 4501), dtype=float32) Tensor(\"batch:1\", shape=(1000, 190), dtype=float32) Tensor(\"Reshape:0\", shape=(1000, 3), dtype=float32) Tensor(\"batch:3\", shape=(1000, 1), dtype=float32)\n",
      "Tensor(\"add_3:0\", shape=(190,), dtype=float32)\n",
      "Tensor(\"batch_1:0\", shape=(1000, 4501), dtype=float32) Tensor(\"batch_1:1\", shape=(1000, 190), dtype=float32) Tensor(\"Reshape_1:0\", shape=(1000, 3), dtype=float32) Tensor(\"batch_1:3\", shape=(1000, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer([(\"D:\\\\AL_DATA\\\\Sr_Li_Al_O_Ver_001\\\\Training\\\\%d.csv\" % i) for i in range(num_files)], \n",
    "                                                    shuffle=True, name='filename_queue')\n",
    "\n",
    "    reader = tf.TextLineReader()\n",
    "    key, value = reader.read(filename_queue)\n",
    "\n",
    "    record_defaults = [[0] for _ in range(X_length)]\n",
    "    record_defaults = [tf.constant([0], dtype=tf.float32) for _ in range(X_length)]\n",
    "\n",
    "    xy_data = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "    xy_data = tf.stack(xy_data)\n",
    "    #xy_data = tf.transpose(xy_data)\n",
    "    \n",
    "    A_1=tf.cast(xy_data[-4], tf.float32)\n",
    "    A_2=tf.cast(xy_data[-3], tf.float32)\n",
    "    A_3=tf.cast(xy_data[-2], tf.float32)\n",
    "    \n",
    "    y_1=tf.cast(xy_data[-7], tf.int32)\n",
    "    y_2=tf.cast(xy_data[-6], tf.int32)\n",
    "    y_3=tf.cast(xy_data[-5], tf.int32)\n",
    "    \n",
    "    y_1 = tf.cond(tf.greater_equal(A_1, 0.8), lambda:y_1+152, lambda:y_1)\n",
    "    y_1 = tf.cond(tf.greater_equal(A_1, 0.6) & tf.less(A_1, 0.8), lambda:y_1+114, lambda:y_1)\n",
    "    y_1 = tf.cond(tf.greater_equal(A_1, 0.4) & tf.less(A_1, 0.6), lambda:y_1+76, lambda:y_1)\n",
    "    y_1 = tf.cond(tf.greater_equal(A_1, 0.2) & tf.less(A_1, 0.4), lambda:y_1+38, lambda:y_1)\n",
    "    \n",
    "    y_2 = tf.cond(tf.greater_equal(A_2, 0.8), lambda:y_2+152, lambda:y_2)\n",
    "    y_2 = tf.cond(tf.greater_equal(A_2, 0.6) & tf.less(A_2, 0.8), lambda:y_2+114, lambda:y_2)\n",
    "    y_2 = tf.cond(tf.greater_equal(A_2, 0.4) & tf.less(A_2, 0.6), lambda:y_2+76, lambda:y_2)\n",
    "    y_2 = tf.cond(tf.greater_equal(A_2, 0.2) & tf.less(A_2, 0.4), lambda:y_2+38, lambda:y_2)\n",
    "   \n",
    "    y_3 = tf.cond(tf.greater_equal(A_3, 0.8), lambda:y_3+152, lambda:y_3)\n",
    "    y_3 = tf.cond(tf.greater_equal(A_3, 0.6) & tf.less(A_3, 0.8), lambda:y_3+114, lambda:y_3)\n",
    "    y_3 = tf.cond(tf.greater_equal(A_3, 0.4) & tf.less(A_3, 0.6), lambda:y_3+76, lambda:y_3)\n",
    "    y_3 = tf.cond(tf.greater_equal(A_3, 0.2) & tf.less(A_3, 0.4), lambda:y_3+38, lambda:y_3)\n",
    "   \n",
    "    \n",
    "    \n",
    "    y_1=tf.one_hot(y_1, n_classes*level_num)\n",
    "    y_2=tf.one_hot(y_2, n_classes*level_num)\n",
    "    y_3=tf.one_hot(y_3, n_classes*level_num)\n",
    "\n",
    "   \n",
    "    y_data = y_1 + y_2 + y_3  \n",
    "    \n",
    "    #y_1=y_1*xy_data[-4]\n",
    "    #y_2=y_2*xy_data[-3] \n",
    "    #y_3=y_3*xy_data[-2]\n",
    "    \n",
    "    #y_data_ = tf.stack([y_1, y_2, y_3])  \n",
    "    #y_data_ = tf.reshape(y_data_, [114])\n",
    "    \n",
    "    y_data = tf.to_float(y_data)\n",
    "    \n",
    "    print(y_data)\n",
    "    \n",
    "    X_train, y_train,  y_train_p, y_train_ind = tf.train.batch([xy_data[:-10], y_data,  xy_data[-4:-1],\n",
    "                                                                xy_data[-1:]], batch_size = batch_size_)\n",
    "    y_train_p, _ = tf.nn.top_k(y_train_p, k=3, sorted=True)\n",
    "    y_train_p = tf.reshape(y_train_p, [batch_size_, 3])\n",
    "    #X_tr, X_vld = tf.split(X_train, [split_size_tr, split_size_vld], 0)\n",
    "    #y_tr, y_vld = tf.split(y_train, [split_size_tr, split_size_vld], 0)\n",
    "    #y_tr_p, y_vld_p = tf.split(y_train_p, [split_size_tr, split_size_vld], 0)\n",
    "    print(X_train, y_train, y_train_p, y_train_ind)\n",
    "#==========================================================================VALIDATION SET==========================================\n",
    "\n",
    "\n",
    "    filename_queue_vld = tf.train.string_input_producer([(\"D:\\\\AL_DATA\\\\Sr_Li_Al_O_Ver_001\\\\Validation\\\\%d.csv\" % i) \n",
    "                                                         for i in range(vld_num_files)], shuffle=True, name='filename_queue')\n",
    "    \n",
    "    \n",
    "    reader_vld = tf.TextLineReader()\n",
    "    key, value_vld = reader.read(filename_queue)\n",
    "    \n",
    "    record_defaults = [[0] for _ in range(X_length)]\n",
    "    record_defaults = [tf.constant([0], dtype=tf.float32) for _ in range(X_length)]\n",
    "    \n",
    "    xy_data_vld = tf.decode_csv(value_vld, record_defaults=record_defaults)\n",
    "    xy_data_vld = tf.stack(xy_data_vld)\n",
    "    #xy_data = tf.transpose(xy_data)\n",
    "    \n",
    "    A_1_vld=tf.cast(xy_data_vld[-4], tf.float32)\n",
    "    A_2_vld=tf.cast(xy_data_vld[-3], tf.float32)\n",
    "    A_3_vld=tf.cast(xy_data_vld[-2], tf.float32)\n",
    "    \n",
    "    y_1_vld=tf.cast(xy_data_vld[-7], tf.int32)\n",
    "    y_2_vld=tf.cast(xy_data_vld[-6], tf.int32)\n",
    "    y_3_vld=tf.cast(xy_data_vld[-5], tf.int32)\n",
    "    \n",
    "    y_1_vld = tf.cond(tf.greater_equal(A_1_vld, 0.8), lambda:y_1_vld+152, lambda:y_1_vld)\n",
    "    y_1_vld = tf.cond(tf.greater_equal(A_1_vld, 0.6) & tf.less(A_1_vld, 0.8), lambda:y_1_vld+114, lambda:y_1_vld)\n",
    "    y_1_vld = tf.cond(tf.greater_equal(A_1_vld, 0.4) & tf.less(A_1_vld, 0.6), lambda:y_1_vld+76, lambda:y_1_vld)\n",
    "    y_1_vld = tf.cond(tf.greater_equal(A_1_vld, 0.2) & tf.less(A_1_vld, 0.4), lambda:y_1_vld+38, lambda:y_1_vld)\n",
    "    \n",
    "    y_2_vld = tf.cond(tf.greater_equal(A_2_vld, 0.8), lambda:y_2_vld+152, lambda:y_2_vld)\n",
    "    y_2_vld = tf.cond(tf.greater_equal(A_2_vld, 0.6) & tf.less(A_2_vld, 0.8), lambda:y_2_vld+114, lambda:y_2_vld)\n",
    "    y_2_vld = tf.cond(tf.greater_equal(A_2_vld, 0.4) & tf.less(A_2_vld, 0.6), lambda:y_2_vld+76, lambda:y_2_vld)\n",
    "    y_2_vld = tf.cond(tf.greater_equal(A_2_vld, 0.2) & tf.less(A_2_vld, 0.4), lambda:y_2_vld+38, lambda:y_2_vld)\n",
    "   \n",
    "    y_3_vld = tf.cond(tf.greater_equal(A_3_vld, 0.8), lambda:y_3_vld+152, lambda:y_3_vld)\n",
    "    y_3_vld = tf.cond(tf.greater_equal(A_3_vld, 0.6) & tf.less(A_3_vld, 0.8), lambda:y_3_vld+114, lambda:y_3_vld)\n",
    "    y_3_vld = tf.cond(tf.greater_equal(A_3_vld, 0.4) & tf.less(A_3_vld, 0.6), lambda:y_3_vld+76, lambda:y_3_vld)\n",
    "    y_3_vld = tf.cond(tf.greater_equal(A_3_vld, 0.2) & tf.less(A_3_vld, 0.4), lambda:y_3_vld+38, lambda:y_3_vld)\n",
    "        \n",
    "     \n",
    "    y_1_vld=tf.one_hot(y_1_vld, n_classes*level_num)\n",
    "    y_2_vld=tf.one_hot(y_2_vld, n_classes*level_num)\n",
    "    y_3_vld=tf.one_hot(y_3_vld, n_classes*level_num)\n",
    "    \n",
    "\n",
    "    y_data_vld = y_1_vld + y_2_vld + y_3_vld\n",
    "\n",
    "\n",
    "    y_data_vld = tf.to_float(y_data_vld)\n",
    "\n",
    "    print(y_data_vld)\n",
    "    \n",
    "    X_vld, y_vld, y_vld_p, y_vld_ind = tf.train.batch([xy_data_vld[:-10], y_data_vld, xy_data_vld[-4:-1], \n",
    "                                                       xy_data_vld[-1:]], batch_size = batch_size_)\n",
    "    y_vld_p, _ = tf.nn.top_k(y_vld_p, k=3, sorted=True)\n",
    "    y_vld_p = tf.reshape(y_vld_p, [batch_size_, 3])\n",
    "    #X_tr, X_vld = tf.split(X_train, [split_size_tr, split_size_vld], 0)\n",
    "    #y_tr, y_vld = tf.split(y_train, [split_size_tr, split_size_vld], 0)\n",
    "    #y_tr_p, y_vld_p = tf.split(y_train_p, [split_size_tr, split_size_vld], 0)\n",
    "    print(X_vld, y_vld, y_vld_p, y_vld_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-75cfa56a96ab>:16: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv1d instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-75cfa56a96ab>:17: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling1d instead.\n",
      "(?, 2251, 64)\n",
      "(?, 1126, 64)\n",
      "(?, 563, 64)\n",
      "(?, 282, 64)\n",
      "(?, 141, 64)\n",
      "WARNING:tensorflow:From <ipython-input-3-75cfa56a96ab>:47: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From <ipython-input-3-75cfa56a96ab>:53: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-3-75cfa56a96ab>:55: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n",
      "WARNING:tensorflow:From <ipython-input-3-75cfa56a96ab>:59: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\sohn\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    inputs_ = tf.placeholder(tf.float32, [None, X_length_, 1], name = 'inputs')\n",
    "\n",
    "    labels_1 = tf.placeholder(tf.float32, [None, n_classes*level_num], name = 'labels_1')\n",
    "\n",
    "    logit_num = tf.placeholder(tf.int32, [None, 3], name = 'logits_Top_3')\n",
    "    label_num = tf.placeholder(tf.int32, [None, 3], name = 'labels_Top_3')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')\n",
    " \n",
    "\n",
    "   #-------------------------------------------------------------------------------------------------------------------------- \n",
    "       \n",
    "    conv = tf.layers.conv1d(inputs=inputs_, filters=64, kernel_size=30, strides=1,padding='same', kernel_initializer=tf.contrib.layers.xavier_initializer(), activation = tf.nn.relu)\n",
    "    max_pool = tf.layers.max_pooling1d(inputs=conv, pool_size=3, strides=2, padding='same')\n",
    "    print(max_pool.shape)\n",
    "    \n",
    "    conv1 = tf.layers.conv1d(inputs=max_pool, filters=64, kernel_size=25, strides=1,padding='same', kernel_initializer=tf.contrib.layers.xavier_initializer(), activation = tf.nn.relu)\n",
    "    max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=3, strides=2, padding='same')\n",
    "    print(max_pool_1.shape)\n",
    "      \n",
    "    conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=64, kernel_size=20, strides=1, padding='same', kernel_initializer=tf.contrib.layers.xavier_initializer(), activation = tf.nn.relu)\n",
    "    max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "    print(max_pool_2.shape)\n",
    "    \n",
    "    conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=64, kernel_size=15, strides=1, padding='same', kernel_initializer=tf.contrib.layers.xavier_initializer(), activation = tf.nn.relu)\n",
    "    max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=1, strides=2, padding='same')\n",
    "    print(max_pool_3.shape)\n",
    "    \n",
    "    conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=64, kernel_size=10, strides=1, padding='same', kernel_initializer=tf.contrib.layers.xavier_initializer(), activation = tf.nn.relu)\n",
    "    max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=1, strides=2, padding='same')\n",
    "    print(max_pool_4.shape)\n",
    "    \n",
    "    #-------------------------------------------------------------------------------------------------------------------------- \n",
    "    # Construct the LSTM inputs and LSTM cells\n",
    "    lstm_in = tf.transpose(max_pool_4, [1,0,2]) # reshape into (seq_len, N, channels)\n",
    "    \n",
    "    seq_len=lstm_in.shape[0]\n",
    "    n_channels=lstm_in.shape[2]\n",
    "    lstm_size = lstm_in.shape[2]*level_num\n",
    "    \n",
    "    lstm_in = tf.reshape(lstm_in, [-1, n_channels]) # Now (seq_len*N, n_channels)\n",
    "    \n",
    "    # To cells\n",
    "    lstm_in = tf.layers.dense(lstm_in, lstm_size, activation=None) # or tf.nn.relu, tf.nn.sigmoid, tf.nn.tanh?\n",
    "    \n",
    "    # Open up the tensor into a list of seq_len pieces\n",
    "    lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "    \n",
    "    # Add LSTM layers\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "    \n",
    "    outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32,\n",
    "                                                     initial_state = initial_state)\n",
    "    \n",
    "    # We only need the last output tensor to pass into a classifier\n",
    "    logits_1 = tf.layers.dense(outputs[-1], n_classes*level_num, name='logits')\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    #cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_1, labels=labels_))\n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_1,labels=labels_1))\n",
    "    \n",
    "    # Grad clipping\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate_)\n",
    "\n",
    "    gradients = train_op.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    optimizer = train_op.apply_gradients(capped_gradients)\n",
    "    \n",
    "    # Accuracy\n",
    "    #correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    correct_pred = tf.equal(logit_num, label_num)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')    \n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-7f243c15d4dd>:18: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "Epoch: 0/1 Iteration: 1 Train loss: 0.693148 Train acc: 0.040667\n",
      "Epoch: 0/1 Iteration: 2 Train loss: 0.674672 Train acc: 0.041333\n",
      "Epoch: 0/1 Iteration: 3 Train loss: 0.583201 Train acc: 0.043667\n",
      "Epoch: 0/1 Iteration: 4 Train loss: 0.498759 Train acc: 0.040333\n",
      "Epoch: 0/1 Iteration: 5 Train loss: 0.426757 Train acc: 0.043333\n",
      "Epoch: 0/1 Iteration: 5 Validation loss: 0.324521 Validation acc: 0.042333\n",
      "Epoch: 0/1 Iteration: 6 Train loss: 0.361942 Train acc: 0.037000\n",
      "Epoch: 0/1 Iteration: 7 Train loss: 0.303807 Train acc: 0.051000\n",
      "Epoch: 0/1 Iteration: 8 Train loss: 0.253372 Train acc: 0.042000\n",
      "Epoch: 0/1 Iteration: 9 Train loss: 0.208799 Train acc: 0.047333\n",
      "Epoch: 0/1 Iteration: 10 Train loss: 0.174880 Train acc: 0.050333\n",
      "Epoch: 0/1 Iteration: 10 Validation loss: 0.116342 Validation acc: 0.059333\n",
      "Epoch: 0/1 Iteration: 11 Train loss: 0.148276 Train acc: 0.042333\n",
      "Epoch: 0/1 Iteration: 12 Train loss: 0.129374 Train acc: 0.036667\n",
      "Epoch: 0/1 Iteration: 13 Train loss: 0.115464 Train acc: 0.042000\n",
      "Epoch: 0/1 Iteration: 14 Train loss: 0.104411 Train acc: 0.046667\n",
      "Epoch: 0/1 Iteration: 15 Train loss: 0.098509 Train acc: 0.042333\n",
      "Epoch: 0/1 Iteration: 15 Validation loss: 0.081235 Validation acc: 0.051000\n",
      "Epoch: 0/1 Iteration: 16 Train loss: 0.093622 Train acc: 0.045000\n",
      "Epoch: 0/1 Iteration: 17 Train loss: 0.091206 Train acc: 0.041000\n",
      "Epoch: 0/1 Iteration: 18 Train loss: 0.088290 Train acc: 0.044333\n",
      "Epoch: 0/1 Iteration: 19 Train loss: 0.087419 Train acc: 0.044667\n",
      "Epoch: 0/1 Iteration: 20 Train loss: 0.086831 Train acc: 0.046667\n",
      "Epoch: 0/1 Iteration: 20 Validation loss: 0.080298 Validation acc: 0.070000\n",
      "Epoch: 0/1 Iteration: 21 Train loss: 0.086134 Train acc: 0.044000\n",
      "Epoch: 0/1 Iteration: 22 Train loss: 0.085501 Train acc: 0.048000\n",
      "Epoch: 0/1 Iteration: 23 Train loss: 0.085022 Train acc: 0.059667\n",
      "Epoch: 0/1 Iteration: 24 Train loss: 0.085534 Train acc: 0.057333\n",
      "Epoch: 0/1 Iteration: 25 Train loss: 0.085013 Train acc: 0.066333\n",
      "Epoch: 0/1 Iteration: 25 Validation loss: 0.080298 Validation acc: 0.082333\n",
      "Epoch: 0/1 Iteration: 26 Train loss: 0.084766 Train acc: 0.065000\n",
      "Epoch: 0/1 Iteration: 27 Train loss: 0.084281 Train acc: 0.081333\n",
      "Epoch: 0/1 Iteration: 28 Train loss: 0.085411 Train acc: 0.067667\n",
      "Epoch: 0/1 Iteration: 29 Train loss: 0.084858 Train acc: 0.066000\n",
      "Epoch: 0/1 Iteration: 30 Train loss: 0.084431 Train acc: 0.079000\n",
      "Epoch: 0/1 Iteration: 30 Validation loss: 0.080585 Validation acc: 0.076000\n",
      "Epoch: 0/1 Iteration: 31 Train loss: 0.084570 Train acc: 0.068333\n",
      "Epoch: 0/1 Iteration: 32 Train loss: 0.084119 Train acc: 0.072333\n",
      "Epoch: 0/1 Iteration: 33 Train loss: 0.084142 Train acc: 0.077667\n",
      "Epoch: 0/1 Iteration: 34 Train loss: 0.084037 Train acc: 0.074667\n",
      "Epoch: 0/1 Iteration: 35 Train loss: 0.084381 Train acc: 0.058000\n",
      "Epoch: 0/1 Iteration: 35 Validation loss: 0.079716 Validation acc: 0.077333\n",
      "Epoch: 0/1 Iteration: 36 Train loss: 0.084573 Train acc: 0.070333\n",
      "Epoch: 0/1 Iteration: 37 Train loss: 0.083793 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 38 Train loss: 0.084446 Train acc: 0.061333\n",
      "Epoch: 0/1 Iteration: 39 Train loss: 0.083677 Train acc: 0.064667\n",
      "Epoch: 0/1 Iteration: 40 Train loss: 0.083948 Train acc: 0.059667\n",
      "Epoch: 0/1 Iteration: 40 Validation loss: 0.078268 Validation acc: 0.075000\n",
      "Epoch: 0/1 Iteration: 41 Train loss: 0.083743 Train acc: 0.063333\n",
      "Epoch: 0/1 Iteration: 42 Train loss: 0.083439 Train acc: 0.068000\n",
      "Epoch: 0/1 Iteration: 43 Train loss: 0.082879 Train acc: 0.063000\n",
      "Epoch: 0/1 Iteration: 44 Train loss: 0.083155 Train acc: 0.066000\n",
      "Epoch: 0/1 Iteration: 45 Train loss: 0.083563 Train acc: 0.059333\n",
      "Epoch: 0/1 Iteration: 45 Validation loss: 0.077881 Validation acc: 0.075667\n",
      "Epoch: 0/1 Iteration: 46 Train loss: 0.083940 Train acc: 0.058667\n",
      "Epoch: 0/1 Iteration: 47 Train loss: 0.082952 Train acc: 0.060000\n",
      "Epoch: 0/1 Iteration: 48 Train loss: 0.082496 Train acc: 0.061333\n",
      "Epoch: 0/1 Iteration: 49 Train loss: 0.082669 Train acc: 0.062000\n",
      "Epoch: 0/1 Iteration: 50 Train loss: 0.082535 Train acc: 0.063667\n",
      "Epoch: 0/1 Iteration: 50 Validation loss: 0.076732 Validation acc: 0.085333\n",
      "Epoch: 0/1 Iteration: 51 Train loss: 0.082183 Train acc: 0.056333\n",
      "Epoch: 0/1 Iteration: 52 Train loss: 0.082394 Train acc: 0.073000\n",
      "Epoch: 0/1 Iteration: 53 Train loss: 0.082455 Train acc: 0.063000\n",
      "Epoch: 0/1 Iteration: 54 Train loss: 0.082821 Train acc: 0.057333\n",
      "Epoch: 0/1 Iteration: 55 Train loss: 0.082192 Train acc: 0.067000\n",
      "Epoch: 0/1 Iteration: 55 Validation loss: 0.076224 Validation acc: 0.079667\n",
      "Epoch: 0/1 Iteration: 56 Train loss: 0.082357 Train acc: 0.055333\n",
      "Epoch: 0/1 Iteration: 57 Train loss: 0.081797 Train acc: 0.064000\n",
      "Epoch: 0/1 Iteration: 58 Train loss: 0.082136 Train acc: 0.065000\n",
      "Epoch: 0/1 Iteration: 59 Train loss: 0.081708 Train acc: 0.065667\n",
      "Epoch: 0/1 Iteration: 60 Train loss: 0.082576 Train acc: 0.060667\n",
      "Epoch: 0/1 Iteration: 60 Validation loss: 0.075769 Validation acc: 0.084333\n",
      "Epoch: 0/1 Iteration: 61 Train loss: 0.082568 Train acc: 0.058667\n",
      "Epoch: 0/1 Iteration: 62 Train loss: 0.082375 Train acc: 0.065667\n",
      "Epoch: 0/1 Iteration: 63 Train loss: 0.081586 Train acc: 0.064667\n",
      "Epoch: 0/1 Iteration: 64 Train loss: 0.082164 Train acc: 0.060667\n",
      "Epoch: 0/1 Iteration: 65 Train loss: 0.082053 Train acc: 0.059667\n",
      "Epoch: 0/1 Iteration: 65 Validation loss: 0.075686 Validation acc: 0.079333\n",
      "Epoch: 0/1 Iteration: 66 Train loss: 0.081211 Train acc: 0.062667\n",
      "Epoch: 0/1 Iteration: 67 Train loss: 0.080880 Train acc: 0.066000\n",
      "Epoch: 0/1 Iteration: 68 Train loss: 0.081652 Train acc: 0.061667\n",
      "Epoch: 0/1 Iteration: 69 Train loss: 0.081562 Train acc: 0.060667\n",
      "Epoch: 0/1 Iteration: 70 Train loss: 0.081210 Train acc: 0.061000\n",
      "Epoch: 0/1 Iteration: 70 Validation loss: 0.074893 Validation acc: 0.087333\n",
      "Epoch: 0/1 Iteration: 71 Train loss: 0.082190 Train acc: 0.060667\n",
      "Epoch: 0/1 Iteration: 72 Train loss: 0.081749 Train acc: 0.058333\n",
      "Epoch: 0/1 Iteration: 73 Train loss: 0.081416 Train acc: 0.060333\n",
      "Epoch: 0/1 Iteration: 74 Train loss: 0.080934 Train acc: 0.056333\n",
      "Epoch: 0/1 Iteration: 75 Train loss: 0.081421 Train acc: 0.066667\n",
      "Epoch: 0/1 Iteration: 75 Validation loss: 0.075322 Validation acc: 0.082667\n",
      "Epoch: 0/1 Iteration: 76 Train loss: 0.081532 Train acc: 0.051667\n",
      "Epoch: 0/1 Iteration: 77 Train loss: 0.081078 Train acc: 0.061000\n",
      "Epoch: 0/1 Iteration: 78 Train loss: 0.081538 Train acc: 0.061667\n",
      "Epoch: 0/1 Iteration: 79 Train loss: 0.081381 Train acc: 0.066333\n",
      "Epoch: 0/1 Iteration: 80 Train loss: 0.081446 Train acc: 0.054667\n",
      "Epoch: 0/1 Iteration: 80 Validation loss: 0.075122 Validation acc: 0.079000\n",
      "Epoch: 0/1 Iteration: 81 Train loss: 0.081001 Train acc: 0.063667\n",
      "Epoch: 0/1 Iteration: 82 Train loss: 0.081875 Train acc: 0.057667\n",
      "Epoch: 0/1 Iteration: 83 Train loss: 0.081115 Train acc: 0.058667\n",
      "Epoch: 0/1 Iteration: 84 Train loss: 0.081950 Train acc: 0.057333\n",
      "Epoch: 0/1 Iteration: 85 Train loss: 0.081074 Train acc: 0.067000\n",
      "Epoch: 0/1 Iteration: 85 Validation loss: 0.075143 Validation acc: 0.079333\n",
      "Epoch: 0/1 Iteration: 86 Train loss: 0.081749 Train acc: 0.062333\n",
      "Epoch: 0/1 Iteration: 87 Train loss: 0.081006 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 88 Train loss: 0.081212 Train acc: 0.061000\n",
      "Epoch: 0/1 Iteration: 89 Train loss: 0.080991 Train acc: 0.055000\n",
      "Epoch: 0/1 Iteration: 90 Train loss: 0.081036 Train acc: 0.060333\n",
      "Epoch: 0/1 Iteration: 90 Validation loss: 0.075219 Validation acc: 0.081000\n",
      "Epoch: 0/1 Iteration: 91 Train loss: 0.080916 Train acc: 0.061000\n",
      "Epoch: 0/1 Iteration: 92 Train loss: 0.080765 Train acc: 0.068333\n",
      "Epoch: 0/1 Iteration: 93 Train loss: 0.080776 Train acc: 0.061333\n",
      "Epoch: 0/1 Iteration: 94 Train loss: 0.080513 Train acc: 0.067333\n",
      "Epoch: 0/1 Iteration: 95 Train loss: 0.081076 Train acc: 0.073333\n",
      "Epoch: 0/1 Iteration: 95 Validation loss: 0.075039 Validation acc: 0.073000\n",
      "Epoch: 0/1 Iteration: 96 Train loss: 0.080487 Train acc: 0.062333\n",
      "Epoch: 0/1 Iteration: 97 Train loss: 0.081077 Train acc: 0.056333\n",
      "Epoch: 0/1 Iteration: 98 Train loss: 0.080373 Train acc: 0.066667\n",
      "Epoch: 0/1 Iteration: 99 Train loss: 0.080266 Train acc: 0.064333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1 Iteration: 100 Train loss: 0.080938 Train acc: 0.061000\n",
      "Epoch: 0/1 Iteration: 100 Validation loss: 0.074927 Validation acc: 0.076333\n",
      "Epoch: 0/1 Iteration: 101 Train loss: 0.080415 Train acc: 0.059333\n",
      "Epoch: 0/1 Iteration: 102 Train loss: 0.081284 Train acc: 0.052667\n",
      "Epoch: 0/1 Iteration: 103 Train loss: 0.080635 Train acc: 0.060333\n",
      "Epoch: 0/1 Iteration: 104 Train loss: 0.080530 Train acc: 0.063667\n",
      "Epoch: 0/1 Iteration: 105 Train loss: 0.080687 Train acc: 0.067667\n",
      "Epoch: 0/1 Iteration: 105 Validation loss: 0.075199 Validation acc: 0.075667\n",
      "Epoch: 0/1 Iteration: 106 Train loss: 0.081131 Train acc: 0.056667\n",
      "Epoch: 0/1 Iteration: 107 Train loss: 0.080887 Train acc: 0.060000\n",
      "Epoch: 0/1 Iteration: 108 Train loss: 0.080191 Train acc: 0.069333\n",
      "Epoch: 0/1 Iteration: 109 Train loss: 0.079674 Train acc: 0.073000\n",
      "Epoch: 0/1 Iteration: 110 Train loss: 0.080563 Train acc: 0.067000\n",
      "Epoch: 0/1 Iteration: 110 Validation loss: 0.075050 Validation acc: 0.080333\n",
      "Epoch: 0/1 Iteration: 111 Train loss: 0.081064 Train acc: 0.059667\n",
      "Epoch: 0/1 Iteration: 112 Train loss: 0.080827 Train acc: 0.056000\n",
      "Epoch: 0/1 Iteration: 113 Train loss: 0.080466 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 114 Train loss: 0.080809 Train acc: 0.062667\n",
      "Epoch: 0/1 Iteration: 115 Train loss: 0.080400 Train acc: 0.063000\n",
      "Epoch: 0/1 Iteration: 115 Validation loss: 0.074761 Validation acc: 0.081000\n",
      "Epoch: 0/1 Iteration: 116 Train loss: 0.080010 Train acc: 0.074000\n",
      "Epoch: 0/1 Iteration: 117 Train loss: 0.080571 Train acc: 0.066667\n",
      "Epoch: 0/1 Iteration: 118 Train loss: 0.080826 Train acc: 0.068000\n",
      "Epoch: 0/1 Iteration: 119 Train loss: 0.080296 Train acc: 0.069000\n",
      "Epoch: 0/1 Iteration: 120 Train loss: 0.080965 Train acc: 0.064667\n",
      "Epoch: 0/1 Iteration: 120 Validation loss: 0.074842 Validation acc: 0.087333\n",
      "Epoch: 0/1 Iteration: 121 Train loss: 0.080765 Train acc: 0.060000\n",
      "Epoch: 0/1 Iteration: 122 Train loss: 0.080147 Train acc: 0.067000\n",
      "Epoch: 0/1 Iteration: 123 Train loss: 0.080706 Train acc: 0.062000\n",
      "Epoch: 0/1 Iteration: 124 Train loss: 0.080370 Train acc: 0.067667\n",
      "Epoch: 0/1 Iteration: 125 Train loss: 0.080761 Train acc: 0.064667\n",
      "Epoch: 0/1 Iteration: 125 Validation loss: 0.075178 Validation acc: 0.085333\n",
      "Epoch: 0/1 Iteration: 126 Train loss: 0.080077 Train acc: 0.064000\n",
      "Epoch: 0/1 Iteration: 127 Train loss: 0.080783 Train acc: 0.063000\n",
      "Epoch: 0/1 Iteration: 128 Train loss: 0.080433 Train acc: 0.063000\n",
      "Epoch: 0/1 Iteration: 129 Train loss: 0.080866 Train acc: 0.061333\n",
      "Epoch: 0/1 Iteration: 130 Train loss: 0.080949 Train acc: 0.060667\n",
      "Epoch: 0/1 Iteration: 130 Validation loss: 0.074877 Validation acc: 0.078667\n",
      "Epoch: 0/1 Iteration: 131 Train loss: 0.080855 Train acc: 0.057667\n",
      "Epoch: 0/1 Iteration: 132 Train loss: 0.080596 Train acc: 0.061333\n",
      "Epoch: 0/1 Iteration: 133 Train loss: 0.080315 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 134 Train loss: 0.080226 Train acc: 0.063000\n",
      "Epoch: 0/1 Iteration: 135 Train loss: 0.080054 Train acc: 0.076000\n",
      "Epoch: 0/1 Iteration: 135 Validation loss: 0.074389 Validation acc: 0.090333\n",
      "Epoch: 0/1 Iteration: 136 Train loss: 0.079917 Train acc: 0.065000\n",
      "Epoch: 0/1 Iteration: 137 Train loss: 0.080559 Train acc: 0.066333\n",
      "Epoch: 0/1 Iteration: 138 Train loss: 0.080428 Train acc: 0.061333\n",
      "Epoch: 0/1 Iteration: 139 Train loss: 0.080240 Train acc: 0.059333\n",
      "Epoch: 0/1 Iteration: 140 Train loss: 0.080285 Train acc: 0.063000\n",
      "Epoch: 0/1 Iteration: 140 Validation loss: 0.074537 Validation acc: 0.079667\n",
      "Epoch: 0/1 Iteration: 141 Train loss: 0.080310 Train acc: 0.066667\n",
      "Epoch: 0/1 Iteration: 142 Train loss: 0.080209 Train acc: 0.068000\n",
      "Epoch: 0/1 Iteration: 143 Train loss: 0.079300 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 144 Train loss: 0.079323 Train acc: 0.074000\n",
      "Epoch: 0/1 Iteration: 145 Train loss: 0.080382 Train acc: 0.062000\n",
      "Epoch: 0/1 Iteration: 145 Validation loss: 0.075084 Validation acc: 0.079667\n",
      "Epoch: 0/1 Iteration: 146 Train loss: 0.080364 Train acc: 0.062333\n",
      "Epoch: 0/1 Iteration: 147 Train loss: 0.080492 Train acc: 0.064667\n",
      "Epoch: 0/1 Iteration: 148 Train loss: 0.079875 Train acc: 0.067667\n",
      "Epoch: 0/1 Iteration: 149 Train loss: 0.080142 Train acc: 0.063333\n",
      "Epoch: 0/1 Iteration: 150 Train loss: 0.080602 Train acc: 0.058667\n",
      "Epoch: 0/1 Iteration: 150 Validation loss: 0.074898 Validation acc: 0.082000\n",
      "Epoch: 0/1 Iteration: 151 Train loss: 0.079940 Train acc: 0.061667\n",
      "Epoch: 0/1 Iteration: 152 Train loss: 0.080143 Train acc: 0.057667\n",
      "Epoch: 0/1 Iteration: 153 Train loss: 0.080182 Train acc: 0.061000\n",
      "Epoch: 0/1 Iteration: 154 Train loss: 0.080145 Train acc: 0.063667\n",
      "Epoch: 0/1 Iteration: 155 Train loss: 0.080317 Train acc: 0.059667\n",
      "Epoch: 0/1 Iteration: 155 Validation loss: 0.074649 Validation acc: 0.086667\n",
      "Epoch: 0/1 Iteration: 156 Train loss: 0.079836 Train acc: 0.059333\n",
      "Epoch: 0/1 Iteration: 157 Train loss: 0.079631 Train acc: 0.076667\n",
      "Epoch: 0/1 Iteration: 158 Train loss: 0.080207 Train acc: 0.060333\n",
      "Epoch: 0/1 Iteration: 159 Train loss: 0.079987 Train acc: 0.067333\n",
      "Epoch: 0/1 Iteration: 160 Train loss: 0.079976 Train acc: 0.066000\n",
      "Epoch: 0/1 Iteration: 160 Validation loss: 0.074665 Validation acc: 0.082333\n",
      "Epoch: 0/1 Iteration: 161 Train loss: 0.080182 Train acc: 0.066333\n",
      "Epoch: 0/1 Iteration: 162 Train loss: 0.079750 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 163 Train loss: 0.079949 Train acc: 0.066000\n",
      "Epoch: 0/1 Iteration: 164 Train loss: 0.079996 Train acc: 0.069000\n",
      "Epoch: 0/1 Iteration: 165 Train loss: 0.080495 Train acc: 0.066667\n",
      "Epoch: 0/1 Iteration: 165 Validation loss: 0.075215 Validation acc: 0.078000\n",
      "Epoch: 0/1 Iteration: 166 Train loss: 0.078947 Train acc: 0.069333\n",
      "Epoch: 0/1 Iteration: 167 Train loss: 0.079823 Train acc: 0.059333\n",
      "Epoch: 0/1 Iteration: 168 Train loss: 0.079994 Train acc: 0.065667\n",
      "Epoch: 0/1 Iteration: 169 Train loss: 0.079895 Train acc: 0.064000\n",
      "Epoch: 0/1 Iteration: 170 Train loss: 0.080038 Train acc: 0.061333\n",
      "Epoch: 0/1 Iteration: 170 Validation loss: 0.074672 Validation acc: 0.079333\n",
      "Epoch: 0/1 Iteration: 171 Train loss: 0.079461 Train acc: 0.064333\n",
      "Epoch: 0/1 Iteration: 172 Train loss: 0.079933 Train acc: 0.064000\n",
      "Epoch: 0/1 Iteration: 173 Train loss: 0.079778 Train acc: 0.064667\n",
      "Epoch: 0/1 Iteration: 174 Train loss: 0.080033 Train acc: 0.061000\n",
      "Epoch: 0/1 Iteration: 175 Train loss: 0.079877 Train acc: 0.061667\n",
      "Epoch: 0/1 Iteration: 175 Validation loss: 0.074670 Validation acc: 0.082333\n",
      "Epoch: 0/1 Iteration: 176 Train loss: 0.079490 Train acc: 0.067000\n",
      "Epoch: 0/1 Iteration: 177 Train loss: 0.080662 Train acc: 0.055667\n",
      "Epoch: 0/1 Iteration: 178 Train loss: 0.079790 Train acc: 0.065000\n",
      "Epoch: 0/1 Iteration: 179 Train loss: 0.079882 Train acc: 0.057667\n",
      "Epoch: 0/1 Iteration: 180 Train loss: 0.079405 Train acc: 0.066000\n",
      "Epoch: 0/1 Iteration: 180 Validation loss: 0.074747 Validation acc: 0.082667\n",
      "Epoch: 0/1 Iteration: 181 Train loss: 0.079706 Train acc: 0.066000\n",
      "Epoch: 0/1 Iteration: 182 Train loss: 0.079839 Train acc: 0.053667\n",
      "Epoch: 0/1 Iteration: 183 Train loss: 0.079832 Train acc: 0.064333\n",
      "Epoch: 0/1 Iteration: 184 Train loss: 0.078973 Train acc: 0.067333\n",
      "Epoch: 0/1 Iteration: 185 Train loss: 0.080032 Train acc: 0.061667\n",
      "Epoch: 0/1 Iteration: 185 Validation loss: 0.074681 Validation acc: 0.077667\n",
      "Epoch: 0/1 Iteration: 186 Train loss: 0.079212 Train acc: 0.073333\n",
      "Epoch: 0/1 Iteration: 187 Train loss: 0.079844 Train acc: 0.066333\n",
      "Epoch: 0/1 Iteration: 188 Train loss: 0.079627 Train acc: 0.064333\n",
      "Epoch: 0/1 Iteration: 189 Train loss: 0.079851 Train acc: 0.062333\n",
      "Epoch: 0/1 Iteration: 190 Train loss: 0.079817 Train acc: 0.064333\n",
      "Epoch: 0/1 Iteration: 190 Validation loss: 0.074807 Validation acc: 0.080000\n",
      "Epoch: 0/1 Iteration: 191 Train loss: 0.079371 Train acc: 0.062333\n",
      "Epoch: 0/1 Iteration: 192 Train loss: 0.079208 Train acc: 0.066333\n",
      "Epoch: 0/1 Iteration: 193 Train loss: 0.079206 Train acc: 0.061667\n",
      "Epoch: 0/1 Iteration: 194 Train loss: 0.079465 Train acc: 0.062000\n",
      "Epoch: 0/1 Iteration: 195 Train loss: 0.079373 Train acc: 0.066333\n",
      "Epoch: 0/1 Iteration: 195 Validation loss: 0.074631 Validation acc: 0.076000\n",
      "Epoch: 0/1 Iteration: 196 Train loss: 0.079694 Train acc: 0.065000\n",
      "Epoch: 0/1 Iteration: 197 Train loss: 0.079438 Train acc: 0.063333\n",
      "Epoch: 0/1 Iteration: 198 Train loss: 0.079391 Train acc: 0.066667\n",
      "Epoch: 0/1 Iteration: 199 Train loss: 0.079250 Train acc: 0.064000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1 Iteration: 200 Train loss: 0.078792 Train acc: 0.066333\n",
      "Epoch: 0/1 Iteration: 200 Validation loss: 0.074358 Validation acc: 0.082333\n",
      "Epoch: 0/1 Iteration: 201 Train loss: 0.078937 Train acc: 0.066667\n",
      "Epoch: 0/1 Iteration: 202 Train loss: 0.079311 Train acc: 0.070333\n",
      "Epoch: 0/1 Iteration: 203 Train loss: 0.079211 Train acc: 0.071667\n",
      "Epoch: 0/1 Iteration: 204 Train loss: 0.079277 Train acc: 0.070333\n",
      "Epoch: 0/1 Iteration: 205 Train loss: 0.079504 Train acc: 0.063667\n",
      "Epoch: 0/1 Iteration: 205 Validation loss: 0.074586 Validation acc: 0.080333\n",
      "Epoch: 0/1 Iteration: 206 Train loss: 0.079636 Train acc: 0.067000\n",
      "Epoch: 0/1 Iteration: 207 Train loss: 0.079767 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 208 Train loss: 0.079228 Train acc: 0.072000\n",
      "Epoch: 0/1 Iteration: 209 Train loss: 0.079632 Train acc: 0.059667\n",
      "Epoch: 0/1 Iteration: 210 Train loss: 0.079039 Train acc: 0.075333\n",
      "Epoch: 0/1 Iteration: 210 Validation loss: 0.074193 Validation acc: 0.087000\n",
      "Epoch: 0/1 Iteration: 211 Train loss: 0.079327 Train acc: 0.072333\n",
      "Epoch: 0/1 Iteration: 212 Train loss: 0.078726 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 213 Train loss: 0.079450 Train acc: 0.061000\n",
      "Epoch: 0/1 Iteration: 214 Train loss: 0.078793 Train acc: 0.072000\n",
      "Epoch: 0/1 Iteration: 215 Train loss: 0.079352 Train acc: 0.063667\n",
      "Epoch: 0/1 Iteration: 215 Validation loss: 0.074195 Validation acc: 0.082667\n",
      "Epoch: 0/1 Iteration: 216 Train loss: 0.079610 Train acc: 0.065000\n",
      "Epoch: 0/1 Iteration: 217 Train loss: 0.079248 Train acc: 0.069000\n",
      "Epoch: 0/1 Iteration: 218 Train loss: 0.078990 Train acc: 0.062333\n",
      "Epoch: 0/1 Iteration: 219 Train loss: 0.079054 Train acc: 0.059333\n",
      "Epoch: 0/1 Iteration: 220 Train loss: 0.079152 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 220 Validation loss: 0.074331 Validation acc: 0.084667\n",
      "Epoch: 0/1 Iteration: 221 Train loss: 0.079406 Train acc: 0.066333\n",
      "Epoch: 0/1 Iteration: 222 Train loss: 0.079031 Train acc: 0.073000\n",
      "Epoch: 0/1 Iteration: 223 Train loss: 0.078651 Train acc: 0.074667\n",
      "Epoch: 0/1 Iteration: 224 Train loss: 0.078979 Train acc: 0.065667\n",
      "Epoch: 0/1 Iteration: 225 Train loss: 0.079364 Train acc: 0.069000\n",
      "Epoch: 0/1 Iteration: 225 Validation loss: 0.074244 Validation acc: 0.078000\n",
      "Epoch: 0/1 Iteration: 226 Train loss: 0.079536 Train acc: 0.068000\n",
      "Epoch: 0/1 Iteration: 227 Train loss: 0.079390 Train acc: 0.065667\n",
      "Epoch: 0/1 Iteration: 228 Train loss: 0.078906 Train acc: 0.077333\n",
      "Epoch: 0/1 Iteration: 229 Train loss: 0.078994 Train acc: 0.069667\n",
      "Epoch: 0/1 Iteration: 230 Train loss: 0.079198 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 230 Validation loss: 0.074361 Validation acc: 0.082333\n",
      "Epoch: 0/1 Iteration: 231 Train loss: 0.078820 Train acc: 0.069667\n",
      "Epoch: 0/1 Iteration: 232 Train loss: 0.078485 Train acc: 0.062000\n",
      "Epoch: 0/1 Iteration: 233 Train loss: 0.078986 Train acc: 0.071333\n",
      "Epoch: 0/1 Iteration: 234 Train loss: 0.079476 Train acc: 0.068333\n",
      "Epoch: 0/1 Iteration: 235 Train loss: 0.078578 Train acc: 0.074333\n",
      "Epoch: 0/1 Iteration: 235 Validation loss: 0.074654 Validation acc: 0.076333\n",
      "Epoch: 0/1 Iteration: 236 Train loss: 0.079406 Train acc: 0.060333\n",
      "Epoch: 0/1 Iteration: 237 Train loss: 0.079133 Train acc: 0.063667\n",
      "Epoch: 0/1 Iteration: 238 Train loss: 0.079172 Train acc: 0.061000\n",
      "Epoch: 0/1 Iteration: 239 Train loss: 0.078652 Train acc: 0.073667\n",
      "Epoch: 0/1 Iteration: 240 Train loss: 0.078354 Train acc: 0.070667\n",
      "Epoch: 0/1 Iteration: 240 Validation loss: 0.074238 Validation acc: 0.078333\n",
      "Epoch: 0/1 Iteration: 241 Train loss: 0.078321 Train acc: 0.058667\n",
      "Epoch: 0/1 Iteration: 242 Train loss: 0.078763 Train acc: 0.065000\n",
      "Epoch: 0/1 Iteration: 243 Train loss: 0.078829 Train acc: 0.063667\n",
      "Epoch: 0/1 Iteration: 244 Train loss: 0.079170 Train acc: 0.070000\n",
      "Epoch: 0/1 Iteration: 245 Train loss: 0.078935 Train acc: 0.068000\n",
      "Epoch: 0/1 Iteration: 245 Validation loss: 0.074434 Validation acc: 0.070667\n",
      "Epoch: 0/1 Iteration: 246 Train loss: 0.079504 Train acc: 0.064333\n",
      "Epoch: 0/1 Iteration: 247 Train loss: 0.078427 Train acc: 0.065667\n",
      "Epoch: 0/1 Iteration: 248 Train loss: 0.079198 Train acc: 0.062333\n",
      "Epoch: 0/1 Iteration: 249 Train loss: 0.079368 Train acc: 0.065667\n",
      "Epoch: 0/1 Iteration: 250 Train loss: 0.078988 Train acc: 0.070000\n",
      "Epoch: 0/1 Iteration: 250 Validation loss: 0.074513 Validation acc: 0.077667\n",
      "Epoch: 0/1 Iteration: 251 Train loss: 0.079057 Train acc: 0.072667\n",
      "Epoch: 0/1 Iteration: 252 Train loss: 0.079035 Train acc: 0.071000\n",
      "Epoch: 0/1 Iteration: 253 Train loss: 0.078681 Train acc: 0.068000\n",
      "Epoch: 0/1 Iteration: 254 Train loss: 0.079283 Train acc: 0.061333\n",
      "Epoch: 0/1 Iteration: 255 Train loss: 0.079256 Train acc: 0.073667\n",
      "Epoch: 0/1 Iteration: 255 Validation loss: 0.074278 Validation acc: 0.077000\n",
      "Epoch: 0/1 Iteration: 256 Train loss: 0.078627 Train acc: 0.071000\n",
      "Epoch: 0/1 Iteration: 257 Train loss: 0.079069 Train acc: 0.068333\n",
      "Epoch: 0/1 Iteration: 258 Train loss: 0.078932 Train acc: 0.061667\n",
      "Epoch: 0/1 Iteration: 259 Train loss: 0.078483 Train acc: 0.067333\n",
      "Epoch: 0/1 Iteration: 260 Train loss: 0.078786 Train acc: 0.062000\n",
      "Epoch: 0/1 Iteration: 260 Validation loss: 0.074679 Validation acc: 0.077667\n",
      "Epoch: 0/1 Iteration: 261 Train loss: 0.078495 Train acc: 0.074333\n",
      "Epoch: 0/1 Iteration: 262 Train loss: 0.078863 Train acc: 0.069333\n",
      "Epoch: 0/1 Iteration: 263 Train loss: 0.078880 Train acc: 0.065667\n",
      "Epoch: 0/1 Iteration: 264 Train loss: 0.078627 Train acc: 0.065667\n",
      "Epoch: 0/1 Iteration: 265 Train loss: 0.078688 Train acc: 0.064333\n",
      "Epoch: 0/1 Iteration: 265 Validation loss: 0.074281 Validation acc: 0.077333\n",
      "Epoch: 0/1 Iteration: 266 Train loss: 0.079058 Train acc: 0.075333\n",
      "Epoch: 0/1 Iteration: 267 Train loss: 0.078789 Train acc: 0.072000\n",
      "Epoch: 0/1 Iteration: 268 Train loss: 0.078487 Train acc: 0.061000\n",
      "Epoch: 0/1 Iteration: 269 Train loss: 0.078717 Train acc: 0.071667\n",
      "Epoch: 0/1 Iteration: 270 Train loss: 0.079301 Train acc: 0.057667\n",
      "Epoch: 0/1 Iteration: 270 Validation loss: 0.074610 Validation acc: 0.080333\n",
      "Epoch: 0/1 Iteration: 271 Train loss: 0.079154 Train acc: 0.064667\n",
      "Epoch: 0/1 Iteration: 272 Train loss: 0.078057 Train acc: 0.071667\n",
      "Epoch: 0/1 Iteration: 273 Train loss: 0.078157 Train acc: 0.071000\n",
      "Epoch: 0/1 Iteration: 274 Train loss: 0.078740 Train acc: 0.067333\n",
      "Epoch: 0/1 Iteration: 275 Train loss: 0.078432 Train acc: 0.072000\n",
      "Epoch: 0/1 Iteration: 275 Validation loss: 0.074402 Validation acc: 0.083333\n",
      "Epoch: 0/1 Iteration: 276 Train loss: 0.079083 Train acc: 0.064333\n",
      "Epoch: 0/1 Iteration: 277 Train loss: 0.078650 Train acc: 0.073000\n",
      "Epoch: 0/1 Iteration: 278 Train loss: 0.078361 Train acc: 0.071000\n",
      "Epoch: 0/1 Iteration: 279 Train loss: 0.078574 Train acc: 0.067000\n",
      "Epoch: 0/1 Iteration: 280 Train loss: 0.078483 Train acc: 0.069667\n",
      "Epoch: 0/1 Iteration: 280 Validation loss: 0.074394 Validation acc: 0.083000\n",
      "Epoch: 0/1 Iteration: 281 Train loss: 0.079096 Train acc: 0.063333\n",
      "Epoch: 0/1 Iteration: 282 Train loss: 0.078974 Train acc: 0.063000\n",
      "Epoch: 0/1 Iteration: 283 Train loss: 0.078268 Train acc: 0.068333\n",
      "Epoch: 0/1 Iteration: 284 Train loss: 0.077914 Train acc: 0.078667\n",
      "Epoch: 0/1 Iteration: 285 Train loss: 0.078512 Train acc: 0.070667\n",
      "Epoch: 0/1 Iteration: 285 Validation loss: 0.074601 Validation acc: 0.078333\n",
      "Epoch: 0/1 Iteration: 286 Train loss: 0.078408 Train acc: 0.072667\n",
      "Epoch: 0/1 Iteration: 287 Train loss: 0.078533 Train acc: 0.068667\n",
      "Epoch: 0/1 Iteration: 288 Train loss: 0.078472 Train acc: 0.054333\n",
      "Epoch: 0/1 Iteration: 289 Train loss: 0.078218 Train acc: 0.078000\n",
      "Epoch: 0/1 Iteration: 290 Train loss: 0.078879 Train acc: 0.064667\n",
      "Epoch: 0/1 Iteration: 290 Validation loss: 0.074191 Validation acc: 0.080000\n",
      "Epoch: 0/1 Iteration: 291 Train loss: 0.078394 Train acc: 0.067000\n",
      "Epoch: 0/1 Iteration: 292 Train loss: 0.078796 Train acc: 0.064000\n",
      "Epoch: 0/1 Iteration: 293 Train loss: 0.079041 Train acc: 0.069333\n",
      "Epoch: 0/1 Iteration: 294 Train loss: 0.078309 Train acc: 0.062333\n",
      "Epoch: 0/1 Iteration: 295 Train loss: 0.078188 Train acc: 0.070000\n",
      "Epoch: 0/1 Iteration: 295 Validation loss: 0.074397 Validation acc: 0.077667\n",
      "Epoch: 0/1 Iteration: 296 Train loss: 0.078772 Train acc: 0.071000\n",
      "Epoch: 0/1 Iteration: 297 Train loss: 0.077752 Train acc: 0.073667\n",
      "Epoch: 0/1 Iteration: 298 Train loss: 0.078582 Train acc: 0.066000\n",
      "Epoch: 0/1 Iteration: 299 Train loss: 0.077809 Train acc: 0.072000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1 Iteration: 300 Train loss: 0.078383 Train acc: 0.072000\n",
      "Epoch: 0/1 Iteration: 300 Validation loss: 0.074358 Validation acc: 0.078000\n",
      "Epoch: 0/1 Iteration: 301 Train loss: 0.077769 Train acc: 0.077333\n",
      "Epoch: 0/1 Iteration: 302 Train loss: 0.078220 Train acc: 0.075667\n",
      "Epoch: 0/1 Iteration: 303 Train loss: 0.077911 Train acc: 0.074000\n",
      "Epoch: 0/1 Iteration: 304 Train loss: 0.078518 Train acc: 0.064667\n",
      "Epoch: 0/1 Iteration: 305 Train loss: 0.078596 Train acc: 0.068000\n",
      "Epoch: 0/1 Iteration: 305 Validation loss: 0.074432 Validation acc: 0.079000\n",
      "Epoch: 0/1 Iteration: 306 Train loss: 0.078167 Train acc: 0.071000\n",
      "Epoch: 0/1 Iteration: 307 Train loss: 0.078343 Train acc: 0.067000\n",
      "Epoch: 0/1 Iteration: 308 Train loss: 0.078250 Train acc: 0.065667\n",
      "Epoch: 0/1 Iteration: 309 Train loss: 0.078254 Train acc: 0.065000\n",
      "Epoch: 0/1 Iteration: 310 Train loss: 0.077937 Train acc: 0.079667\n",
      "Epoch: 0/1 Iteration: 310 Validation loss: 0.073981 Validation acc: 0.083333\n",
      "Epoch: 0/1 Iteration: 311 Train loss: 0.078631 Train acc: 0.072333\n",
      "Epoch: 0/1 Iteration: 312 Train loss: 0.078206 Train acc: 0.068333\n",
      "Epoch: 0/1 Iteration: 313 Train loss: 0.078519 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 314 Train loss: 0.078026 Train acc: 0.066333\n",
      "Epoch: 0/1 Iteration: 315 Train loss: 0.077611 Train acc: 0.066333\n",
      "Epoch: 0/1 Iteration: 315 Validation loss: 0.074368 Validation acc: 0.082667\n",
      "Epoch: 0/1 Iteration: 316 Train loss: 0.077918 Train acc: 0.075000\n",
      "Epoch: 0/1 Iteration: 317 Train loss: 0.078671 Train acc: 0.066000\n",
      "Epoch: 0/1 Iteration: 318 Train loss: 0.078181 Train acc: 0.073333\n",
      "Epoch: 0/1 Iteration: 319 Train loss: 0.077867 Train acc: 0.072000\n",
      "Epoch: 0/1 Iteration: 320 Train loss: 0.078188 Train acc: 0.069667\n",
      "Epoch: 0/1 Iteration: 320 Validation loss: 0.074697 Validation acc: 0.085333\n",
      "Epoch: 0/1 Iteration: 321 Train loss: 0.077622 Train acc: 0.077333\n",
      "Epoch: 0/1 Iteration: 322 Train loss: 0.077900 Train acc: 0.070000\n",
      "Epoch: 0/1 Iteration: 323 Train loss: 0.078825 Train acc: 0.073667\n",
      "Epoch: 0/1 Iteration: 324 Train loss: 0.078104 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 325 Train loss: 0.077692 Train acc: 0.075667\n",
      "Epoch: 0/1 Iteration: 325 Validation loss: 0.074016 Validation acc: 0.081667\n",
      "Epoch: 0/1 Iteration: 326 Train loss: 0.078335 Train acc: 0.070667\n",
      "Epoch: 0/1 Iteration: 327 Train loss: 0.077728 Train acc: 0.081667\n",
      "Epoch: 0/1 Iteration: 328 Train loss: 0.078113 Train acc: 0.070000\n",
      "Epoch: 0/1 Iteration: 329 Train loss: 0.077815 Train acc: 0.072667\n",
      "Epoch: 0/1 Iteration: 330 Train loss: 0.078146 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 330 Validation loss: 0.073948 Validation acc: 0.083000\n",
      "Epoch: 0/1 Iteration: 331 Train loss: 0.078070 Train acc: 0.068333\n",
      "Epoch: 0/1 Iteration: 332 Train loss: 0.077907 Train acc: 0.074667\n",
      "Epoch: 0/1 Iteration: 333 Train loss: 0.078088 Train acc: 0.067333\n",
      "Epoch: 0/1 Iteration: 334 Train loss: 0.078388 Train acc: 0.064667\n",
      "Epoch: 0/1 Iteration: 335 Train loss: 0.077486 Train acc: 0.081667\n",
      "Epoch: 0/1 Iteration: 335 Validation loss: 0.074054 Validation acc: 0.083333\n",
      "Epoch: 0/1 Iteration: 336 Train loss: 0.077964 Train acc: 0.064667\n",
      "Epoch: 0/1 Iteration: 337 Train loss: 0.077840 Train acc: 0.071333\n",
      "Epoch: 0/1 Iteration: 338 Train loss: 0.077677 Train acc: 0.074000\n",
      "Epoch: 0/1 Iteration: 339 Train loss: 0.077668 Train acc: 0.068667\n",
      "Epoch: 0/1 Iteration: 340 Train loss: 0.077650 Train acc: 0.069000\n",
      "Epoch: 0/1 Iteration: 340 Validation loss: 0.074307 Validation acc: 0.082333\n",
      "Epoch: 0/1 Iteration: 341 Train loss: 0.078125 Train acc: 0.073333\n",
      "Epoch: 0/1 Iteration: 342 Train loss: 0.077917 Train acc: 0.070667\n",
      "Epoch: 0/1 Iteration: 343 Train loss: 0.077917 Train acc: 0.072000\n",
      "Epoch: 0/1 Iteration: 344 Train loss: 0.078256 Train acc: 0.074333\n",
      "Epoch: 0/1 Iteration: 345 Train loss: 0.077934 Train acc: 0.077333\n",
      "Epoch: 0/1 Iteration: 345 Validation loss: 0.074393 Validation acc: 0.084667\n",
      "Epoch: 0/1 Iteration: 346 Train loss: 0.077997 Train acc: 0.072000\n",
      "Epoch: 0/1 Iteration: 347 Train loss: 0.077880 Train acc: 0.067333\n",
      "Epoch: 0/1 Iteration: 348 Train loss: 0.077820 Train acc: 0.075333\n",
      "Epoch: 0/1 Iteration: 349 Train loss: 0.077725 Train acc: 0.072333\n",
      "Epoch: 0/1 Iteration: 350 Train loss: 0.078135 Train acc: 0.069333\n",
      "Epoch: 0/1 Iteration: 350 Validation loss: 0.074334 Validation acc: 0.081333\n",
      "Epoch: 0/1 Iteration: 351 Train loss: 0.077529 Train acc: 0.075000\n",
      "Epoch: 0/1 Iteration: 352 Train loss: 0.077396 Train acc: 0.075000\n",
      "Epoch: 0/1 Iteration: 353 Train loss: 0.077487 Train acc: 0.074333\n",
      "Epoch: 0/1 Iteration: 354 Train loss: 0.077311 Train acc: 0.074000\n",
      "Epoch: 0/1 Iteration: 355 Train loss: 0.077523 Train acc: 0.067000\n",
      "Epoch: 0/1 Iteration: 355 Validation loss: 0.074608 Validation acc: 0.074000\n",
      "Epoch: 0/1 Iteration: 356 Train loss: 0.077131 Train acc: 0.080000\n",
      "Epoch: 0/1 Iteration: 357 Train loss: 0.077885 Train acc: 0.076667\n",
      "Epoch: 0/1 Iteration: 358 Train loss: 0.077860 Train acc: 0.075000\n",
      "Epoch: 0/1 Iteration: 359 Train loss: 0.077833 Train acc: 0.069000\n",
      "Epoch: 0/1 Iteration: 360 Train loss: 0.077843 Train acc: 0.069333\n",
      "Epoch: 0/1 Iteration: 360 Validation loss: 0.074043 Validation acc: 0.079667\n",
      "Epoch: 0/1 Iteration: 361 Train loss: 0.077686 Train acc: 0.069000\n",
      "Epoch: 0/1 Iteration: 362 Train loss: 0.077959 Train acc: 0.070000\n",
      "Epoch: 0/1 Iteration: 363 Train loss: 0.078040 Train acc: 0.073667\n",
      "Epoch: 0/1 Iteration: 364 Train loss: 0.077753 Train acc: 0.067667\n",
      "Epoch: 0/1 Iteration: 365 Train loss: 0.078102 Train acc: 0.067667\n",
      "Epoch: 0/1 Iteration: 365 Validation loss: 0.074299 Validation acc: 0.081333\n",
      "Epoch: 0/1 Iteration: 366 Train loss: 0.077361 Train acc: 0.072667\n",
      "Epoch: 0/1 Iteration: 367 Train loss: 0.077366 Train acc: 0.070667\n",
      "Epoch: 0/1 Iteration: 368 Train loss: 0.077381 Train acc: 0.071333\n",
      "Epoch: 0/1 Iteration: 369 Train loss: 0.077885 Train acc: 0.066000\n",
      "Epoch: 0/1 Iteration: 370 Train loss: 0.077451 Train acc: 0.076667\n",
      "Epoch: 0/1 Iteration: 370 Validation loss: 0.074143 Validation acc: 0.085000\n",
      "Epoch: 0/1 Iteration: 371 Train loss: 0.078084 Train acc: 0.061667\n",
      "Epoch: 0/1 Iteration: 372 Train loss: 0.077919 Train acc: 0.071667\n",
      "Epoch: 0/1 Iteration: 373 Train loss: 0.077747 Train acc: 0.065333\n",
      "Epoch: 0/1 Iteration: 374 Train loss: 0.077634 Train acc: 0.068667\n",
      "Epoch: 0/1 Iteration: 375 Train loss: 0.077714 Train acc: 0.068333\n",
      "Epoch: 0/1 Iteration: 375 Validation loss: 0.074445 Validation acc: 0.076667\n",
      "Epoch: 0/1 Iteration: 376 Train loss: 0.077982 Train acc: 0.062000\n",
      "Epoch: 0/1 Iteration: 377 Train loss: 0.077996 Train acc: 0.067000\n",
      "Epoch: 0/1 Iteration: 378 Train loss: 0.077691 Train acc: 0.067333\n",
      "Epoch: 0/1 Iteration: 379 Train loss: 0.077346 Train acc: 0.073333\n",
      "Epoch: 0/1 Iteration: 380 Train loss: 0.077356 Train acc: 0.074333\n",
      "Epoch: 0/1 Iteration: 380 Validation loss: 0.074704 Validation acc: 0.082667\n",
      "Epoch: 0/1 Iteration: 381 Train loss: 0.077821 Train acc: 0.064000\n",
      "Epoch: 0/1 Iteration: 382 Train loss: 0.077641 Train acc: 0.071000\n",
      "Epoch: 0/1 Iteration: 383 Train loss: 0.077788 Train acc: 0.064667\n",
      "Epoch: 0/1 Iteration: 384 Train loss: 0.077701 Train acc: 0.073000\n",
      "Epoch: 0/1 Iteration: 385 Train loss: 0.077161 Train acc: 0.078667\n",
      "Epoch: 0/1 Iteration: 385 Validation loss: 0.074632 Validation acc: 0.078000\n",
      "Epoch: 0/1 Iteration: 386 Train loss: 0.077995 Train acc: 0.063667\n",
      "Epoch: 0/1 Iteration: 387 Train loss: 0.077916 Train acc: 0.064000\n",
      "Epoch: 0/1 Iteration: 388 Train loss: 0.077774 Train acc: 0.064667\n",
      "Epoch: 0/1 Iteration: 389 Train loss: 0.077399 Train acc: 0.072333\n",
      "Epoch: 0/1 Iteration: 390 Train loss: 0.077683 Train acc: 0.069667\n",
      "Epoch: 0/1 Iteration: 390 Validation loss: 0.074241 Validation acc: 0.081000\n",
      "Epoch: 0/1 Iteration: 391 Train loss: 0.077344 Train acc: 0.067000\n",
      "Epoch: 0/1 Iteration: 392 Train loss: 0.077184 Train acc: 0.067667\n",
      "Epoch: 0/1 Iteration: 393 Train loss: 0.077773 Train acc: 0.067333\n",
      "Epoch: 0/1 Iteration: 394 Train loss: 0.077657 Train acc: 0.070667\n",
      "Epoch: 0/1 Iteration: 395 Train loss: 0.077184 Train acc: 0.068333\n",
      "Epoch: 0/1 Iteration: 395 Validation loss: 0.073683 Validation acc: 0.084667\n",
      "Epoch: 0/1 Iteration: 396 Train loss: 0.077268 Train acc: 0.077667\n",
      "Epoch: 0/1 Iteration: 397 Train loss: 0.077424 Train acc: 0.078333\n",
      "Epoch: 0/1 Iteration: 398 Train loss: 0.077200 Train acc: 0.074667\n",
      "Epoch: 0/1 Iteration: 399 Train loss: 0.077730 Train acc: 0.073333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1 Iteration: 400 Train loss: 0.077697 Train acc: 0.071667\n",
      "Epoch: 0/1 Iteration: 400 Validation loss: 0.074102 Validation acc: 0.078333\n",
      "Epoch: 0/1 Iteration: 401 Train loss: 0.076732 Train acc: 0.075667\n",
      "Epoch: 0/1 Iteration: 402 Train loss: 0.077046 Train acc: 0.079333\n",
      "Epoch: 0/1 Iteration: 403 Train loss: 0.077752 Train acc: 0.068333\n",
      "Epoch: 0/1 Iteration: 404 Train loss: 0.077689 Train acc: 0.067667\n",
      "Epoch: 0/1 Iteration: 405 Train loss: 0.077179 Train acc: 0.072000\n",
      "Epoch: 0/1 Iteration: 405 Validation loss: 0.073967 Validation acc: 0.081333\n",
      "Epoch: 0/1 Iteration: 406 Train loss: 0.076663 Train acc: 0.068000\n",
      "Epoch: 0/1 Iteration: 407 Train loss: 0.077292 Train acc: 0.068000\n",
      "Epoch: 0/1 Iteration: 408 Train loss: 0.077288 Train acc: 0.066000\n",
      "Epoch: 0/1 Iteration: 409 Train loss: 0.077250 Train acc: 0.068667\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Session has been closed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7f243c15d4dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m             \u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_ind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m             \u001b[1;31m#X_tr_a, X_vld_a, y_tr_a, y_vld_a = train_test_split(X_tr, y_tr, test_size=0.2, random_state=42)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "with tf.Session(graph=graph) as sess:\n",
    "\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #saver.restore(sess, tf.train.latest_checkpoint('D:\\\\AL_DATA\\\\Sr_Li_Al_O_Ver_001\\\\checkpoints-cnn'))\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    \n",
    "    # check data\n",
    "        \n",
    "    iteration = 1\n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "\n",
    "        # Loop over batches\n",
    "        for i in  range(600):    \n",
    "            state = sess.run(initial_state)\n",
    "\n",
    "\n",
    "            X_tr, y_tr, y_ind = sess.run([X_train, y_train, y_train_ind])\n",
    "            #X_tr_a, X_vld_a, y_tr_a, y_vld_a = train_test_split(X_tr, y_tr, test_size=0.2, random_state=42)\n",
    "            \n",
    "            \n",
    "            X_tr= np.reshape(X_tr, (-1, 4501, 1)) \n",
    "\n",
    "         \n",
    "            feed = {inputs_ : X_tr, labels_1 : y_tr,  keep_prob_ : 0.5, initial_state : state, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , logit, state= sess.run([cost, optimizer, logits_1, final_state], feed_dict = feed)            \n",
    "            \n",
    "            \n",
    "            y_lab = np.empty([batch_size_, 3])\n",
    "            y_logit = np.empty([batch_size_, 3])\n",
    "            \n",
    "            for i in range(batch_size_):\n",
    "                if y_ind[i,0] == 2:\n",
    "                    \n",
    "                    y_lab[i]=np.argsort(y_tr[i])[-3:]\n",
    "                    y_lab[i]=np.sort(y_lab[i])\n",
    "                    \n",
    "                    y_logit[i]=np.argsort(logit[i])[-3:]\n",
    "                    y_logit[i]=np.sort(y_logit[i])\n",
    "                    \n",
    "                elif y_ind[i,0] == 1:\n",
    "                    \n",
    "                    z=np.argsort(y_tr[i])[-2:]\n",
    "                    y_lab[i]=np.append(z, [0])\n",
    "                    y_lab[i]=np.sort(y_lab[i])\n",
    "                    \n",
    "                    z_=np.argsort(logit[i])[-2:]\n",
    "                    y_logit[i]=np.append(z_, [0])\n",
    "                    y_logit[i]=np.sort(y_logit[i])\n",
    "                    \n",
    "                elif y_ind[i,0] == 0:\n",
    "                    \n",
    "                    z=np.argsort(y_tr[i])[-1:]\n",
    "                    y_lab[i]=np.append(z, [0,0])\n",
    "                    y_lab[i]=np.sort(y_lab[i])\n",
    "                    \n",
    "                    z_=np.argsort(logit[i])[-1:]\n",
    "                    y_logit[i]=np.append(z_, [0,0])\n",
    "                    y_logit[i]=np.sort(y_logit[i])\n",
    "                else:\n",
    "                    print('Something Wrong happened!!!')       \n",
    " \n",
    "            \n",
    "            feed = {logit_num : y_logit, label_num: y_lab}\n",
    "\n",
    "            acc = sess.run(accuracy, feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)                   \n",
    "\n",
    "            print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                    \"Iteration: {:d}\".format(iteration),\n",
    "                    \"Train loss: {:6f}\".format(loss),\n",
    "                    \"Train acc: {:.6f}\".format(acc))\n",
    "\n",
    "###================================================================ VALIDATION =====================================\n",
    "            if (iteration %5 == 0):\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                X_vd, y_vd,  y_ind_vd = sess.run([X_vld, y_vld,  y_vld_ind])\n",
    "                X_vd= np.reshape(X_vd, (-1, 4501, 1))\n",
    "            \n",
    "\n",
    "                feed = {inputs_ : X_vd, labels_1 : y_vd,  keep_prob_ : 1.0, initial_state : val_state}\n",
    "            \n",
    "                # Loss\n",
    "                loss_vd,  logit_vd , state_v= sess.run([cost,  logits_1, final_state], feed_dict = feed)            \n",
    "                \n",
    "            \n",
    "                y_lab_vd = np.empty([batch_size_, 3])\n",
    "                y_logit_vd = np.empty([batch_size_, 3])\n",
    "\n",
    "\n",
    "                for i in range(batch_size_):\n",
    "                    if y_ind_vd[i,0] == 2:\n",
    "                    \n",
    "                        y_lab_vd[i]=np.argsort(y_vd[i])[-3:]\n",
    "                        y_lab_vd[i]=np.sort(y_lab_vd[i])\n",
    "                        \n",
    "                        y_logit_vd[i]=np.argsort(logit_vd[i])[-3:]\n",
    "                        y_logit_vd[i]=np.sort(y_logit_vd[i])\n",
    "                    \n",
    "                    elif y_ind_vd[i,0] == 1:\n",
    "                    \n",
    "                        z=np.argsort(y_vd[i])[-2:]\n",
    "                        y_lab_vd[i]=np.append(z, [0])\n",
    "                        y_lab_vd[i]=np.sort(y_lab_vd[i])\n",
    "                    \n",
    "                        z_=np.argsort(logit_vd[i])[-2:]\n",
    "                        y_logit_vd[i]=np.append(z_, [0])\n",
    "                        y_logit_vd[i]=np.sort(y_logit_vd[i])\n",
    "                    \n",
    "                    elif y_ind_vd[i,0] == 0:\n",
    "                    \n",
    "                        z=np.argsort(y_vd[i])[-1:]\n",
    "                        y_lab_vd[i]=np.append(z, [0,0])\n",
    "                        y_lab_vd[i]=np.sort(y_lab_vd[i])\n",
    "                    \n",
    "                        z_=np.argsort(logit_vd[i])[-1:]\n",
    "                        y_logit_vd[i]=np.append(z_, [0,0])\n",
    "                        y_logit_vd[i]=np.sort(y_logit_vd[i])\n",
    "                    else:\n",
    "                        print('Something Wrong happened!!!')\n",
    "                feed_1 = {logit_num : y_logit_vd, label_num: y_lab_vd}\n",
    "            \n",
    "                # Loss\n",
    "                acc_vd = sess.run(accuracy, feed_dict = feed_1)\n",
    "                train_acc.append(acc_vd)\n",
    "                train_loss.append(loss_vd)            \n",
    "\n",
    "\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                        \"Iteration: {:d}\".format(iteration),\n",
    "                        \"Validation loss: {:6f}\".format(loss_vd),\n",
    "                        \"Validation acc: {:.6f}\".format(acc_vd))\n",
    "                \n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(acc_vd)\n",
    "                validation_loss.append(loss_vd)\n",
    "            \n",
    "            iteration += 1 \n",
    "            \n",
    "        saver.save(sess,\"D:\\\\AL_DATA\\\\Sr_Li_Al_O_Ver_001\\\\checkpoints-cnn\\\\xrd_class.ckpt\")\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
